{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375b48ee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-30T07:22:46.457514Z",
     "iopub.status.busy": "2023-04-30T07:22:46.456700Z",
     "iopub.status.idle": "2023-04-30T07:22:46.491542Z",
     "shell.execute_reply": "2023-04-30T07:22:46.490291Z"
    },
    "papermill": {
     "duration": 0.045927,
     "end_time": "2023-04-30T07:22:46.494280",
     "exception": false,
     "start_time": "2023-04-30T07:22:46.448353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/translated-small-parabank2/translated_small_parabank2_postproc.tsv\n",
      "/kaggle/input/slopara-gpt/model/config.json\n",
      "/kaggle/input/slopara-gpt/model/trainer_state.json\n",
      "/kaggle/input/slopara-gpt/model/training_args.bin\n",
      "/kaggle/input/slopara-gpt/model/tokenizer.json\n",
      "/kaggle/input/slopara-gpt/model/tokenizer_config.json\n",
      "/kaggle/input/slopara-gpt/model/pytorch_model.bin\n",
      "/kaggle/input/slopara-gpt/model/scaler.pt\n",
      "/kaggle/input/slopara-gpt/model/scheduler.pt\n",
      "/kaggle/input/slopara-gpt/model/special_tokens_map.json\n",
      "/kaggle/input/slopara-gpt/model/optimizer.pt\n",
      "/kaggle/input/slopara-gpt/model/rng_state.pth\n",
      "/kaggle/input/slopara-gpt/model/generation_config.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0e392b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:22:46.506584Z",
     "iopub.status.busy": "2023-04-30T07:22:46.506157Z",
     "iopub.status.idle": "2023-04-30T07:22:50.874970Z",
     "shell.execute_reply": "2023-04-30T07:22:50.873525Z"
    },
    "papermill": {
     "duration": 4.378396,
     "end_time": "2023-04-30T07:22:50.877922",
     "exception": false,
     "start_time": "2023-04-30T07:22:46.499526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c48254d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:22:50.889954Z",
     "iopub.status.busy": "2023-04-30T07:22:50.889358Z",
     "iopub.status.idle": "2023-04-30T07:22:50.894151Z",
     "shell.execute_reply": "2023-04-30T07:22:50.893211Z"
    },
    "papermill": {
     "duration": 0.013522,
     "end_time": "2023-04-30T07:22:50.896531",
     "exception": false,
     "start_time": "2023-04-30T07:22:50.883009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"/kaggle/input/slopara-gpt/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc96fa91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:22:50.908432Z",
     "iopub.status.busy": "2023-04-30T07:22:50.908024Z",
     "iopub.status.idle": "2023-04-30T07:23:01.995148Z",
     "shell.execute_reply": "2023-04-30T07:23:01.993433Z"
    },
    "papermill": {
     "duration": 11.09643,
     "end_time": "2023-04-30T07:23:01.998033",
     "exception": false,
     "start_time": "2023-04-30T07:22:50.901603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcdbd416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:02.010854Z",
     "iopub.status.busy": "2023-04-30T07:23:02.010382Z",
     "iopub.status.idle": "2023-04-30T07:23:02.028190Z",
     "shell.execute_reply": "2023-04-30T07:23:02.026849Z"
    },
    "papermill": {
     "duration": 0.027448,
     "end_time": "2023-04-30T07:23:02.030872",
     "exception": false,
     "start_time": "2023-04-30T07:23:02.003424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(60032, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): FastGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=60032, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83258dff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:02.043877Z",
     "iopub.status.busy": "2023-04-30T07:23:02.043105Z",
     "iopub.status.idle": "2023-04-30T07:23:02.051830Z",
     "shell.execute_reply": "2023-04-30T07:23:02.050442Z"
    },
    "papermill": {
     "duration": 0.018003,
     "end_time": "2023-04-30T07:23:02.054306",
     "exception": false,
     "start_time": "2023-04-30T07:23:02.036303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_paraphrase(input_text, n_sent=5):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "    in_len = len(input_ids[0])\n",
    "    output = model.generate(input_ids, \n",
    "                            do_sample=True, \n",
    "                            max_length=int(in_len*3), \n",
    "                            top_p=0.95, \n",
    "                            top_k=50, \n",
    "                            temperature=0.7, \n",
    "                            num_beams=2, \n",
    "                            num_return_sequences=n_sent, \n",
    "                            pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    output_text = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    #print(\"\\n\".join(output_text))\n",
    "    out = [o[len(input_text)+2:] for o in output_text]\n",
    "    return list(set(out)) #make unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cec8b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:02.067829Z",
     "iopub.status.busy": "2023-04-30T07:23:02.067029Z",
     "iopub.status.idle": "2023-04-30T07:23:10.847676Z",
     "shell.execute_reply": "2023-04-30T07:23:10.846303Z"
    },
    "papermill": {
     "duration": 8.791071,
     "end_time": "2023-04-30T07:23:10.850838",
     "exception": false,
     "start_time": "2023-04-30T07:23:02.059767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Vsaj enkrat se strinjam s tabo. \n",
      "   vsaj enkrat sem se strinjal s tabo.\n"
     ]
    }
   ],
   "source": [
    "n_sent = 5\n",
    "input_text = \"Vsaj enkrat se strinjam s tabo.\"\n",
    "#input_text = \"to je čudovito mesto in bombardirali so ga.\"\n",
    "#input_text = \"Močan socialni dialog je skupna značilnost držav, v katerih so se trgi dela izkazali za bolj krizne.\"\n",
    "para = generate_paraphrase(input_text,n_sent)\n",
    "print(input_text,\"\\n  \", \"\\n  \".join(para))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992e8dc",
   "metadata": {
    "papermill": {
     "duration": 0.005049,
     "end_time": "2023-04-30T07:23:10.861414",
     "exception": false,
     "start_time": "2023-04-30T07:23:10.856365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e566bda5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:10.875110Z",
     "iopub.status.busy": "2023-04-30T07:23:10.873980Z",
     "iopub.status.idle": "2023-04-30T07:23:13.924299Z",
     "shell.execute_reply": "2023-04-30T07:23:13.923003Z"
    },
    "papermill": {
     "duration": 3.060041,
     "end_time": "2023-04-30T07:23:13.926888",
     "exception": false,
     "start_time": "2023-04-30T07:23:10.866847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004 Ocean Cup narodov</td>\n",
       "      <td>Ocean Cup narodov 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004 Ocean Cup narodov</td>\n",
       "      <td>Pokal narodov OFC 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004 Ocean Cup narodov</td>\n",
       "      <td>Ocean Bowl narodov 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ocean Cup narodov 2004</td>\n",
       "      <td>Pokal narodov OFC 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ocean Cup narodov 2004</td>\n",
       "      <td>Ocean Bowl narodov 2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               input_text              output_text\n",
       "0  2004 Ocean Cup narodov   Ocean Cup narodov 2004\n",
       "1  2004 Ocean Cup narodov   Pokal narodov OFC 2004\n",
       "2  2004 Ocean Cup narodov  Ocean Bowl narodov 2004\n",
       "3  Ocean Cup narodov 2004   Pokal narodov OFC 2004\n",
       "4  Ocean Cup narodov 2004  Ocean Bowl narodov 2004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/translated-small-parabank2/translated_small_parabank2_postproc.tsv\", sep=\"\\t\", header=None)\n",
    "df.columns = [\"input_text\",\"output_text\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9982490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:13.941920Z",
     "iopub.status.busy": "2023-04-30T07:23:13.939532Z",
     "iopub.status.idle": "2023-04-30T07:23:13.953628Z",
     "shell.execute_reply": "2023-04-30T07:23:13.952308Z"
    },
    "papermill": {
     "duration": 0.02373,
     "end_time": "2023-04-30T07:23:13.956247",
     "exception": false,
     "start_time": "2023-04-30T07:23:13.932517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69003                            enkrat se strinjam z vami.\n",
       "69004                            enkrat se strinjam z vami.\n",
       "69005                 jaz sem v soglasju z vami, za enkrat.\n",
       "69006                 jaz sem v soglasju z vami, za enkrat.\n",
       "69007                       Vsaj enkrat se strinjam s tabo.\n",
       "                                ...                        \n",
       "690008    Ta uredba se ne uporablja za izvedbene dejavno...\n",
       "690009    Ta uredba se ne uporablja za izvajanje ukrepov...\n",
       "690010    Ta uredba se ne uporablja za izvajanje ukrepov...\n",
       "690011    Ta uredba se ne uporablja za izvajanje dejavno...\n",
       "690012    Ta uredba nadomešča odločbo evropske stranke i...\n",
       "Name: input_text, Length: 621010, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[69003:690013].input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5edc87f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:13.970666Z",
     "iopub.status.busy": "2023-04-30T07:23:13.969674Z",
     "iopub.status.idle": "2023-04-30T07:23:23.498362Z",
     "shell.execute_reply": "2023-04-30T07:23:23.496924Z"
    },
    "papermill": {
     "duration": 9.539765,
     "end_time": "2023-04-30T07:23:23.501838",
     "exception": false,
     "start_time": "2023-04-30T07:23:13.962073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a pandas DataFrame 'df' with columns \"input_text\" and \"output_text\"\n",
    "data = df[[\"input_text\", \"output_text\"]].apply(tuple, axis=1).tolist()\n",
    "\n",
    "# Split data into train and temp sets (80% train, 20% temp)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.4, random_state=42)\n",
    "# Split temp_data into eval and test sets (10% eval, 10% test)\n",
    "eval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef9942",
   "metadata": {
    "papermill": {
     "duration": 0.005602,
     "end_time": "2023-04-30T07:23:23.513357",
     "exception": false,
     "start_time": "2023-04-30T07:23:23.507755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea89cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:23.526710Z",
     "iopub.status.busy": "2023-04-30T07:23:23.525986Z",
     "iopub.status.idle": "2023-04-30T07:23:24.255751Z",
     "shell.execute_reply": "2023-04-30T07:23:24.254339Z"
    },
    "papermill": {
     "duration": 0.739659,
     "end_time": "2023-04-30T07:23:24.258591",
     "exception": false,
     "start_time": "2023-04-30T07:23:23.518932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537284965911771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "hypothesis = \"Transformers Transformers are fast plus efficient\".split()\n",
    "reference = [\"HuggingFace Transformers are fast efficient plus awesome\".split(), \n",
    "               \"Transformers are awesome because they are fast to execute\".split(),\n",
    "              \"Transformers are not so slow.\".split()]\n",
    "BLEUscore = sentence_bleu(reference, hypothesis)\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4374be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:24.273709Z",
     "iopub.status.busy": "2023-04-30T07:23:24.273308Z",
     "iopub.status.idle": "2023-04-30T07:23:50.789957Z",
     "shell.execute_reply": "2023-04-30T07:23:50.788212Z"
    },
    "papermill": {
     "duration": 26.528652,
     "end_time": "2023-04-30T07:23:50.793292",
     "exception": false,
     "start_time": "2023-04-30T07:23:24.264640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (23.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.13.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.2)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2023.1.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.11.4)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.4)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.11.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.7.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\r\n",
      "Installing collected packages: evaluate\r\n",
      "Successfully installed evaluate-0.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting rouge-score\r\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.4.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge-score) (3.2.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.21.6)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.16.0)\r\n",
      "Building wheels for collected packages: rouge-score\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=648266ab810a6d15469d921ef99992efcd9d8675fa1ceeaa4c16270bb1fc0b5b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/6b/70/59daa7c90a238610e34bac5916e001fe3d9bb0ec59c8cf5518\r\n",
      "Successfully built rouge-score\r\n",
      "Installing collected packages: rouge-score\r\n",
      "Successfully installed rouge-score-0.1.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7985efa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:50.813091Z",
     "iopub.status.busy": "2023-04-30T07:23:50.812558Z",
     "iopub.status.idle": "2023-04-30T07:23:54.029717Z",
     "shell.execute_reply": "2023-04-30T07:23:54.028234Z"
    },
    "papermill": {
     "duration": 3.231231,
     "end_time": "2023-04-30T07:23:54.032754",
     "exception": false,
     "start_time": "2023-04-30T07:23:50.801523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7bb5fc57d54d21bf2dd5b941523d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.7692307692307692, 'rouge2': 0.3636363636363636, 'rougeL': 0.6153846153846153, 'rougeLsum': 0.6153846153846153}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "predictions = [\"Transformers Transformers are fast plus efficient\"]\n",
    "references = [\n",
    "              [\"HuggingFace Transformers are fast efficient plus awesome\", \n",
    "               \"Transformers are awesome because they are fast to execute\",\n",
    "              \"Transformers are not so slow.\"]\n",
    "\n",
    "]\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f086a",
   "metadata": {
    "papermill": {
     "duration": 0.007937,
     "end_time": "2023-04-30T07:23:54.049300",
     "exception": false,
     "start_time": "2023-04-30T07:23:54.041363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation of paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b7d406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T07:23:54.068556Z",
     "iopub.status.busy": "2023-04-30T07:23:54.066758Z",
     "iopub.status.idle": "2023-04-30T08:37:28.074513Z",
     "shell.execute_reply": "2023-04-30T08:37:28.073254Z"
    },
    "papermill": {
     "duration": 4414.020602,
     "end_time": "2023-04-30T08:37:28.077932",
     "exception": false,
     "start_time": "2023-04-30T07:23:54.057330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(test_data)\n",
    "\n",
    "i=0\n",
    "evaluation = []\n",
    "while i < 1000: #len(df):\n",
    "    s = df.iloc[i,0]\n",
    "    ref = df[df.iloc[:,0]==s].iloc[:,1]\n",
    "    ref = list(ref)\n",
    "    #print(s,ref)\n",
    "    ref = [e.split() for e in ref]\n",
    "    \n",
    "    para = generate_paraphrase(s,5)\n",
    "    \n",
    "    bleuscores = []\n",
    "    for p in para:\n",
    "        b = sentence_bleu(ref, p.split())\n",
    "        bleuscores.append(b)\n",
    "    \n",
    "    bleuscores = np.array(bleuscores)\n",
    "    evaluation.append([s,para[np.argmax(bleuscores)],np.max(bleuscores)])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0970038f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T08:37:28.096176Z",
     "iopub.status.busy": "2023-04-30T08:37:28.095631Z",
     "iopub.status.idle": "2023-04-30T08:37:28.166216Z",
     "shell.execute_reply": "2023-04-30T08:37:28.164999Z"
    },
    "papermill": {
     "duration": 0.082496,
     "end_time": "2023-04-30T08:37:28.168760",
     "exception": false,
     "start_time": "2023-04-30T08:37:28.086264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ne, umrl bi.</td>\n",
       "      <td>ne, ne bi bil mrtev.</td>\n",
       "      <td>0.668740304976422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Močan socialni dialog je skupna značilnost drž...</td>\n",
       "      <td>Močan socialni dialog je skupna značilnost drž...</td>\n",
       "      <td>0.38091370416670794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ali imate kakšno besedo z njim?</td>\n",
       "      <td>Ali imate kakšno besedo z njim?</td>\n",
       "      <td>0.6389431042462724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to je čudovito mesto in bombardirali so ga.</td>\n",
       "      <td>to je čudovito mesto inbombardirali so ga.</td>\n",
       "      <td>0.41113361690051975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Izgube, ki bi jih utrpele banke euroobmočja, b...</td>\n",
       "      <td>Izgube, ki bi jih utrpele banke v euroobmočju,...</td>\n",
       "      <td>0.6504011927452344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>A mi lahko daš odgovor?</td>\n",
       "      <td>Ali lahko dobim vaš odgovor?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>v členu 47 Listine je določen zakon o pravične...</td>\n",
       "      <td>člen 47 Listine določa pravico do poštenega so...</td>\n",
       "      <td>0.345720784641941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Jaz sem jih vse rešil.</td>\n",
       "      <td>rešil sem jih.</td>\n",
       "      <td>0.5444460596606694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Tam mora biti tudi Marrascaud.</td>\n",
       "      <td>Marrascaud mora biti tukaj.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Roberta Bondarove</td>\n",
       "      <td>(angleščina) Roberta Bondarova</td>\n",
       "      <td>0.9036020036098448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0                                         Ne, umrl bi.   \n",
       "1    Močan socialni dialog je skupna značilnost drž...   \n",
       "2                      Ali imate kakšno besedo z njim?   \n",
       "3          to je čudovito mesto in bombardirali so ga.   \n",
       "4    Izgube, ki bi jih utrpele banke euroobmočja, b...   \n",
       "..                                                 ...   \n",
       "995                            A mi lahko daš odgovor?   \n",
       "996  v členu 47 Listine je določen zakon o pravične...   \n",
       "997                             Jaz sem jih vse rešil.   \n",
       "998                     Tam mora biti tudi Marrascaud.   \n",
       "999                                  Roberta Bondarove   \n",
       "\n",
       "                                                     1                    2  \n",
       "0                                 ne, ne bi bil mrtev.    0.668740304976422  \n",
       "1    Močan socialni dialog je skupna značilnost drž...  0.38091370416670794  \n",
       "2                      Ali imate kakšno besedo z njim?   0.6389431042462724  \n",
       "3           to je čudovito mesto inbombardirali so ga.  0.41113361690051975  \n",
       "4    Izgube, ki bi jih utrpele banke v euroobmočju,...   0.6504011927452344  \n",
       "..                                                 ...                  ...  \n",
       "995                       Ali lahko dobim vaš odgovor?                    0  \n",
       "996  člen 47 Listine določa pravico do poštenega so...    0.345720784641941  \n",
       "997                                     rešil sem jih.   0.5444460596606694  \n",
       "998                        Marrascaud mora biti tukaj.                    0  \n",
       "999                    (angleščina) Roberta Bondarova    0.9036020036098448  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = np.array(evaluation)\n",
    "pe = pd.DataFrame(e)\n",
    "pe.to_csv(\"/kaggle/working/paraphrase_evaluation.tsv\", sep=\"\\t\")\n",
    "#np.savetxt(\"/kaggle/working/paraphrase_evaluation.tsv\", e, delimiter=\"\\t\")\n",
    "pd.DataFrame(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4495.270917,
   "end_time": "2023-04-30T08:37:31.465385",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-30T07:22:36.194468",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "18f6e84ddc724653a3de2772722f52a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "191a3d7ea027410f801cb8f54b7232e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18f6e84ddc724653a3de2772722f52a9",
       "placeholder": "​",
       "style": "IPY_MODEL_fa31d0a28d8849c086d46b108b4e3c76",
       "value": " 6.27k/6.27k [00:00&lt;00:00, 375kB/s]"
      }
     },
     "487fc65a023d40b3b6980bbcc3dccfc5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f597724cd3f49ef85957d4dad027f90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7e7bb5fc57d54d21bf2dd5b941523d72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b96763be70c04fa894228fb4af9983ee",
        "IPY_MODEL_be49a348c6b6496aafd534fc34199731",
        "IPY_MODEL_191a3d7ea027410f801cb8f54b7232e0"
       ],
       "layout": "IPY_MODEL_487fc65a023d40b3b6980bbcc3dccfc5"
      }
     },
     "b96763be70c04fa894228fb4af9983ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f647e13f112e4426bbdc430c33ad2236",
       "placeholder": "​",
       "style": "IPY_MODEL_f66b67a8c7734c27a1fbe33c3cb04b8f",
       "value": "Downloading builder script: 100%"
      }
     },
     "be49a348c6b6496aafd534fc34199731": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eb6b67bbf4664162b0a577a661f6e314",
       "max": 6270.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5f597724cd3f49ef85957d4dad027f90",
       "value": 6270.0
      }
     },
     "eb6b67bbf4664162b0a577a661f6e314": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f647e13f112e4426bbdc430c33ad2236": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f66b67a8c7734c27a1fbe33c3cb04b8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fa31d0a28d8849c086d46b108b4e3c76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
