@article{Demsar2016BalancedMixture,
    title = {{A Balanced Mixture of Antagonistic Pressures Promotes the Evolution of Parallel Movement}},
    year = {2016},
    journal = {Scientific Reports},
    author = {Dem{\v{s}}ar, Jure and {\v{S}}trumbelj, Erik and Lebar Bajec, Iztok},
    volume = {6},
    doi = {10.1038/srep39428}
}

@article{Demsar2017LinguisticEvolution,
    title = {{Evolution of Collective Behaviour in an Artificial World Using Linguistic Fuzzy Rule-Based Systems}},
    year = {2017},
    journal = {PLoS ONE},
    author = {Dem{\v{s}}ar, Jure and Lebar Bajec, Iztok},
    number = {1},
    pages = {1--20},
    volume = {12},
    doi = {10.1371/journal.pone.0168876}
}

@inproceedings{mckeown-1979-paraphrasing,
    title = "Paraphrasing Using Given and New Information in a Question-Answer System",
    author = "McKeown, Kathleen R.",
    booktitle = "17th Annual Meeting of the Association for Computational Linguistics",
    month = jun,
    year = "1979",
    address = "La Jolla, California, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P79-1016",
    doi = "10.3115/982163.982182",
    pages = "67--72",
}

@inproceedings{10.3115/1073012.1073020,
author = {Barzilay, Regina and McKeown, Kathleen R.},
title = {Extracting Paraphrases from a Parallel Corpus},
year = {2001},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073012.1073020},
doi = {10.3115/1073012.1073020},
abstract = {While paraphrasing is critical both for interpretation and generation of natural language, current systems use manual or semi-automatic methods to collect paraphrases. We present an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text. Our approach yields phrasal and single word lexical paraphrases as well as syntactic paraphrases.},
booktitle = {Proceedings of the 39th Annual Meeting on Association for Computational Linguistics},
pages = {50â€“57},
numpages = {8},
location = {Toulouse, France},
series = {ACL '01}
}

@inproceedings{mallinson-etal-2017-paraphrasing,
    title = "Paraphrasing Revisited with Neural Machine Translation",
    author = "Mallinson, Jonathan  and
      Sennrich, Rico  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E17-1083",
    pages = "881--893",
    abstract = "Recognizing and generating paraphrases is an important component in many natural language processing applications. A well-established technique for automatically extracting paraphrases leverages bilingual corpora to find meaning-equivalent phrases in a single language by {``}pivoting{''} over a shared translation in another language. In this paper we revisit bilingual pivoting in the context of neural machine translation and present a paraphrasing model based purely on neural networks. Our model represents paraphrases in a continuous space, estimates the degree of semantic relatedness between text segments of arbitrary length, and generates candidate paraphrases for any source input. Experimental results across tasks and datasets show that neural paraphrases outperform those obtained with conventional phrase-based pivoting approaches.",
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{DBLP:journals/corr/abs-1911-09661,
  author    = {Sam Witteveen and
               Martin Andrews},
  title     = {Paraphrasing with Large Language Models},
  journal   = {CoRR},
  volume    = {abs/1911.09661},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.09661},
  eprinttype = {arXiv},
  eprint    = {1911.09661},
  timestamp = {Tue, 03 Dec 2019 14:15:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-09661.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{paraphrasingtoimproveqa,
  title={Improving the robustness of question answering systems to question paraphrasing},
  author={Gan, Wee Chung and Ng, Hwee Tou},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={6065--6075},
  year={2019}
}

@inproceedings{li-etal-2018-paraphrase,
    title = "Paraphrase Generation with Deep Reinforcement Learning",
    author = "Li, Zichao  and
      Jiang, Xin  and
      Shang, Lifeng  and
      Li, Hang",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1421",
    doi = "10.18653/v1/D18-1421",
    pages = "3865--3878",
    abstract = "Automatic generation of paraphrases from a given sentence is an important yet challenging task in natural language processing (NLP). In this paper, we present a deep reinforcement learning approach to paraphrase generation. Specifically, we propose a new framework for the task, which consists of a generator and an evaluator, both of which are learned from data. The generator, built as a sequence-to-sequence learning model, can produce paraphrases given a sentence. The evaluator, constructed as a deep matching model, can judge whether two sentences are paraphrases of each other. The generator is first trained by deep learning and then further fine-tuned by reinforcement learning in which the reward is given by the evaluator. For the learning of the evaluator, we propose two methods based on supervised learning and inverse reinforcement learning respectively, depending on the type of available training data. Experimental results on two datasets demonstrate the proposed models (the generators) can produce more accurate paraphrases and outperform the state-of-the-art methods in paraphrase generation in both automatic evaluation and human evaluation.",
}

@inproceedings{paraphrasestodetectorigin,
  title={Using paraphrases for improving first story detection in news and Twitter},
  author={Petrovi{\'c}, Sa{\v{s}}a and Osborne, Miles and Lavrenko, Victor},
  booktitle={Proceedings of the 2012 conference of the north american chapter of the association for computational linguistics: Human language technologies},
  pages={338--346},
  year={2012}
}

@inproceedings{paraphrasestoevaluatetext,
  title={Paraeval: Using paraphrases to evaluate summaries automatically},
  author={Zhou, Liang and Lin, Chin-Yew and Munteanu, Dragos Stefan and Hovy, Eduard},
  booktitle={Proceedings of the human language technology conference of the NAACL, main conference},
  pages={447--454},
  year={2006}
}


@inproceedings{scherrer-2020-tapaco,
    title = "{T}a{P}a{C}o: A Corpus of Sentential Paraphrases for 73 Languages",
    author = "Scherrer, Yves",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.848",
    pages = "6868--6873",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@misc{rsdo4_en_sl,
 title = {Parallel corpus {EN}-{SL} {RSDO4} 1.0},
 author = {Repar, Andra{\v z} and Lebar Bajec, Iztok},
 url = {http://hdl.handle.net/11356/1457},
 year = {2021}
}

@misc{mT5-base,
  doi = {10.48550/ARXIV.2010.11934},
  url = {https://arxiv.org/abs/2010.11934},
  author = {Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {mT5: A massively multilingual pre-trained text-to-text transformer},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{dale2021howT5,
  title={How to Adapt a Multilingual T5 Model for a Single Language},
  author={Dale, David},
  journal={Towards Data Science},
  year={2021},
  howpublished = {\url{https://towardsdatascience.com/how-to-adapt-a-multilingual-t5-model-for-a-single-language-b9f94f3d9c90}}
}

@inproceedings{hosking-etal-2022-hierarchical,
    title = "Hierarchical Sketch Induction for Paraphrase Generation",
    author = "Hosking, Tom  and
      Tang, Hao  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.178",
    pages = "2489--2501",
}


@misc{parascore,
  doi = {10.48550/ARXIV.2202.08479},
  url = {https://arxiv.org/abs/2202.08479},
  author = {Shen, Lingfeng and Liu, Lemao and Jiang, Haiyun and Shi, Shuming},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {On the Evaluation Metrics for Paraphrase Generation},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{cao-wan-2020-divgan-pbleu,
    title = "{D}iv{GAN}: Towards Diverse Paraphrase Generation via Diversified Generative Adversarial Network",
    author = "Cao, Yue  and
      Wan, Xiaojun",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.218",
    doi = "10.18653/v1/2020.findings-emnlp.218",
    pages = "2411--2421"
}


@inproceedings{ibleu2011,
  author={Madnani, Nitin},
  booktitle={2011 IEEE Fifth International Conference on Semantic Computing}, 
  title={iBLEU: Interactively Debugging and Scoring Statistical Machine Translation Systems}, 
  year={2011},
  volume={},
  number={},
  pages={213-214},
  doi={10.1109/ICSC.2011.36}
}